{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from  tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"../Data/01 - The Fellowship Of The Ring.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt1 = file.read()\n",
    "\n",
    "with open(\"../Data/02 - The Two Towers.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt2 = file.read()\n",
    "\n",
    "with open(\"../Data/03 - The Return Of The King.txt\",\"r\",encoding='utf-8') as file:\n",
    "    raw_txt3 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "raw_txt = raw_txt1 + raw_txt2 + raw_txt3\n",
    "# Not beautiful\n",
    "stripped_txt = raw_txt.replace('\\n\\n', ' ').replace('\\t', ' ').replace('\\r', ' ')\\\n",
    "    .replace(';', '').replace(':', '').replace('  ', ' ')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I chose to keep \\n and punctuation to get a more fun output at the end, but it did reduce the accuracy slightly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "vocab = list(set(stripped_txt))\n",
    "vocab.sort()\n",
    "vocab_dict = {}\n",
    "for i, character in enumerate(vocab):\n",
    "    identity_vector = torch.zeros(len(vocab))\n",
    "    identity_vector[i] = 1\n",
    "    vocab_dict[character] = identity_vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# L\n",
    "L = 15\n",
    "dataX = torch.zeros((len(stripped_txt) - L, L, len(vocab_dict)))\n",
    "dataY = torch.zeros(len(stripped_txt) - L)\n",
    "for i in range(len(stripped_txt) - L):\n",
    "    x = torch.zeros((L, len(vocab_dict)))\n",
    "    for j in range(L):\n",
    "        x[j] = vocab_dict[stripped_txt[i+j]]\n",
    "    dataX[i] = x\n",
    "    dataY[i] = torch.argmax(vocab_dict[stripped_txt[i+L]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "h\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "r\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "e\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "e\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      " \n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "R\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "i\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "n\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "g\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "s\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      " \n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "f\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "o\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      "r\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.])\n",
      " \n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "reversed_dict = {}\n",
    "for key in vocab_dict:\n",
    "    reversed_dict[torch.argmax(vocab_dict[key]).item()] = key\n",
    "for x in dataX[0]:\n",
    "    print(reversed_dict[torch.argmax(x).item()])\n",
    "    print(x)\n",
    "print(reversed_dict[dataY[0].item()])\n",
    "print(dataY[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MobyDickDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.Y[idx]\n",
    "        return (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2548876\n"
     ]
    }
   ],
   "source": [
    "dataset = MobyDickDataset(dataX, dataY)\n",
    "print(len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [2400000, 148876])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=8192, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=256, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class MyLSTM(torch.nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, feature_size, hidden_size, nr_of_stacks, output_dim):\n",
    "        super().__init__()\n",
    "        self.LSTM = torch.nn.LSTM(feature_size, hidden_size, nr_of_stacks, batch_first=True)\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h, c) = self.LSTM(x)\n",
    "        out = self.linear(h)\n",
    "        out = out[0]\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device {device}.\")\n",
    "\n",
    "def train(model, optimizer, loss_f, epochs, train_loader):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        loss_train = 0.0\n",
    "        train_bar = tqdm(total=len(train_loader), desc=\"Epoch progression\")\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device=device)\n",
    "            yb = yb.to(device=device)\n",
    "            yb = yb.long()\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                out = model(xb)\n",
    "                loss = loss_f(out, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss_train += loss.item()\n",
    "                train_bar.update()\n",
    "\n",
    "        print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))\n",
    "        train_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:57<00:00,  5.07it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:45:41.206200  |  Epoch 0  |  Training loss 3.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:33<00:00,  8.87it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:46:14.252676  |  Epoch 1  |  Training loss 2.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 11.13it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:46:40.574415  |  Epoch 2  |  Training loss 2.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.94it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:47:10.063265  |  Epoch 3  |  Training loss 2.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:28<00:00, 10.17it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:47:38.873564  |  Epoch 4  |  Training loss 2.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.92it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:48:03.450946  |  Epoch 5  |  Training loss 1.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.93it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<01:01,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:48:26.118939  |  Epoch 6  |  Training loss 1.878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.02it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:47,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:48:48.618489  |  Epoch 7  |  Training loss 1.826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.07it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:49,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:49:11.028732  |  Epoch 8  |  Training loss 1.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.15it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:46,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:49:33.304105  |  Epoch 9  |  Training loss 1.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.08it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:49,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:49:55.699996  |  Epoch 10  |  Training loss 1.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.93it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:54,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:50:20.269113  |  Epoch 11  |  Training loss 1.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.22it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:50:44.246302  |  Epoch 12  |  Training loss 1.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.74it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:51:11.530799  |  Epoch 13  |  Training loss 1.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.71it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:51:38.894400  |  Epoch 14  |  Training loss 1.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.76it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:52:06.113835  |  Epoch 15  |  Training loss 1.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.64it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:52:31.284199  |  Epoch 16  |  Training loss 1.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.53it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:52:56.696445  |  Epoch 17  |  Training loss 1.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.80it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:46,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:53:19.593090  |  Epoch 18  |  Training loss 1.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.16it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:50,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:53:41.850848  |  Epoch 19  |  Training loss 1.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.08it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:45,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:54:04.245189  |  Epoch 20  |  Training loss 1.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.15it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:48,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:54:26.523014  |  Epoch 21  |  Training loss 1.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.48it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:48,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:54:50.001016  |  Epoch 22  |  Training loss 1.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.88it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:55:14.676177  |  Epoch 23  |  Training loss 1.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:30<00:00,  9.53it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:55:45.417762  |  Epoch 24  |  Training loss 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:33<00:00,  8.87it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:54,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:56:18.457017  |  Epoch 25  |  Training loss 1.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 10.92it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:47,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:56:45.290249  |  Epoch 26  |  Training loss 1.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.38it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:51,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:57:11.028180  |  Epoch 27  |  Training loss 1.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.50it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:57:34.464061  |  Epoch 28  |  Training loss 1.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 10.92it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:53,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:58:01.302389  |  Epoch 29  |  Training loss 1.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:30<00:00,  9.67it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:55,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:58:31.597925  |  Epoch 30  |  Training loss 1.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:28<00:00, 10.23it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:58,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:59:00.230690  |  Epoch 31  |  Training loss 1.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:31<00:00,  9.16it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:57,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 13:59:32.231955  |  Epoch 32  |  Training loss 1.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:34<00:00,  8.54it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:00:06.561630  |  Epoch 33  |  Training loss 1.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.92it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:57,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:00:36.102539  |  Epoch 34  |  Training loss 1.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.99it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:53,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:01:05.426572  |  Epoch 35  |  Training loss 1.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 11.12it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:56,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:01:31.771336  |  Epoch 36  |  Training loss 1.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.57it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:01:57.099586  |  Epoch 37  |  Training loss 1.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.11it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:46,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:02:21.294492  |  Epoch 38  |  Training loss 1.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.49it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:54,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:02:44.755419  |  Epoch 39  |  Training loss 1.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.53it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:56,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:03:10.174417  |  Epoch 40  |  Training loss 1.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.75it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:51,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:03:37.440713  |  Epoch 41  |  Training loss 1.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.80it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:56,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:04:07.325481  |  Epoch 42  |  Training loss 1.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:36<00:00,  8.03it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<01:01,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:04:43.828664  |  Epoch 43  |  Training loss 1.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.79it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:52,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:05:13.745099  |  Epoch 44  |  Training loss 1.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.38it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:05:39.497843  |  Epoch 45  |  Training loss 1.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.77it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:59,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:06:04.388665  |  Epoch 46  |  Training loss 1.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.93it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:06:33.882764  |  Epoch 47  |  Training loss 1.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.61it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:06:59.123616  |  Epoch 48  |  Training loss 1.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.36it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:07:24.909551  |  Epoch 49  |  Training loss 1.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00,  9.77it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<01:01,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:07:54.896125  |  Epoch 50  |  Training loss 1.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:31<00:00,  9.33it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:50,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:08:26.290345  |  Epoch 51  |  Training loss 1.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.68it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:08:53.719976  |  Epoch 52  |  Training loss 1.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.12it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:47,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:09:16.053824  |  Epoch 53  |  Training loss 1.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:09:38.030943  |  Epoch 54  |  Training loss 1.370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyLSTM(len(vocab_dict), len(vocab_dict), 1, len(vocab_dict))\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "model.to(device=device)\n",
    "loss.to(device=device)\n",
    "train(model, opt, loss, 55, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def validate(model, val_loader, train_loader):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.59\n",
      "Accuracy val: 0.59\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.59128625, 'val': 0.5869045380047825}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, val_loader, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Farewell, Arag"
     ]
    }
   ],
   "source": [
    "def generate_text(model, seed):\n",
    "    seed = seed.to(device)\n",
    "    for i, t in enumerate(seq_seed_tensor[0]):\n",
    "        print(reversed_dict[torch.argmax(t).item()], end='')\n",
    "\n",
    "    for _ in range(500):\n",
    "        next_c = model(seed)[0]\n",
    "        next_c = torch.softmax(next_c, -1, next_c.dtype)\n",
    "        seed[0,:-1] = seed[0,1:].clone()\n",
    "        seed[0, -1] = vocab_dict[reversed_dict[torch.argmax(next_c).item()]]\n",
    "        print(reversed_dict[torch.argmax(next_c).item()], end='')\n",
    "\n",
    "seq_seed = \"'Farewell, Arag\"\n",
    "\n",
    "seq_seed_tensor = torch.zeros((1, L, len(vocab_dict)))\n",
    "for i, c in enumerate(seq_seed):\n",
    "    seq_seed_tensor[0, i] = vocab_dict[c]\n",
    "\n",
    "\n",
    "for i, t in enumerate(seq_seed_tensor[0]):\n",
    "    print(reversed_dict[torch.argmax(t).item()], end='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Farewell, Aragorn and the stream of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger of the stranger o"
     ]
    }
   ],
   "source": [
    "generate_text(model, seq_seed_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It repeats! This is because it always picks the most probable character which leads to a loop, so we use sampling to\n",
    "get more diversity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def generate_text_with_sampling(model, seed):\n",
    "    seed = seed.to(device)\n",
    "    for i, t in enumerate(seq_seed_tensor[0]):\n",
    "        print(reversed_dict[torch.argmax(t).item()], end='')\n",
    "\n",
    "    for _ in range(1000):\n",
    "        next_c = model(seed)[0]\n",
    "        next_c = torch.softmax(next_c, -1, next_c.dtype)\n",
    "        seed[0,:-1] = seed[0,1:].clone()\n",
    "        test_c = np.random.choice(len(vocab_dict), 1, p=next_c.cpu().detach().numpy())\n",
    "        seed[0, -1] = vocab_dict[reversed_dict[test_c[0]]]\n",
    "        print(reversed_dict[test_c[0]], end='')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Farewell, Aragorn.   Frodo sent you. Not in searly Faramir zabled and it could have far down them then they had not Sam closes, and not had been we won't dover rying all the ring swooding behind.'\n",
      "   'It was rat made white was spoke and some door into time by the Barrow-daybe now Ouch starting throught them on for winiofed of me, he said have suselvested up in a heart of this nam of them. Sam looked himself mind where the mean of Gollum if rather, is than well, and his torestoner!' After it. Yet the Nine?'\n",
      "   Then he should may had gone bight often this way the Orcs erranong her near stief south of the Draurfax.   They good the Gate and drew that Rayurasting doup, can it tollom Ents stirl of flowed and side' han on hwar, and the Fieds remaining that ley bettirst!'\n",
      "   It can myselfary rodough, or to have been gond slowly things. The Many his heading and the altoged, and shice on his off Orcs, the openers seen. They' said Legotho's meen Shrowland they waters of Eorl sinding lasted pother down him, as "
     ]
    }
   ],
   "source": [
    "generate_text_with_sampling(model, seq_seed_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:30<00:00,  9.54it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:10:38.342663  |  Epoch 0  |  Training loss 1.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:30<00:00,  9.63it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:11:08.762117  |  Epoch 1  |  Training loss 1.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:34<00:00,  8.50it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:11:43.250913  |  Epoch 2  |  Training loss 1.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:35<00:00,  8.16it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:58,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:12:19.178037  |  Epoch 3  |  Training loss 1.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:33<00:00,  8.63it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:12:53.134089  |  Epoch 4  |  Training loss 1.360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:29<00:00, 10.07it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:13:22.223370  |  Epoch 5  |  Training loss 1.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 11.01it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:13:48.837357  |  Epoch 6  |  Training loss 1.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.88it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:14:13.496897  |  Epoch 7  |  Training loss 1.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.00it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:14:37.911027  |  Epoch 8  |  Training loss 1.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.70it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:15:00.991994  |  Epoch 9  |  Training loss 1.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.35it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:15:22.934719  |  Epoch 10  |  Training loss 1.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.86it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:15:44.081545  |  Epoch 11  |  Training loss 1.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.68it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:46,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:16:07.195293  |  Epoch 12  |  Training loss 1.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.49it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:52,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:16:30.653626  |  Epoch 13  |  Training loss 1.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.07it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<01:01,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:16:54.936438  |  Epoch 14  |  Training loss 1.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.19it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:56,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:17:17.144296  |  Epoch 15  |  Training loss 1.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.05it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:17:41.469682  |  Epoch 16  |  Training loss 1.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:25<00:00, 11.28it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:18:07.433106  |  Epoch 17  |  Training loss 1.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.16it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:53,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:18:31.533440  |  Epoch 18  |  Training loss 1.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.73it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:18:58.849901  |  Epoch 19  |  Training loss 1.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.60it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:45,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:19:20.403645  |  Epoch 20  |  Training loss 1.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.27it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:41,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:19:42.482065  |  Epoch 21  |  Training loss 1.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.23it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:43,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:20:06.446933  |  Epoch 22  |  Training loss 1.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:26<00:00, 10.97it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:41,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:20:33.163019  |  Epoch 23  |  Training loss 1.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.57it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:55,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:20:54.761098  |  Epoch 24  |  Training loss 1.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.71it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:52,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:21:17.808625  |  Epoch 25  |  Training loss 1.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.69it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:41,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:21:39.215273  |  Epoch 26  |  Training loss 1.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.60it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:22:00.755237  |  Epoch 27  |  Training loss 1.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:28<00:00, 10.23it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:22:29.398887  |  Epoch 28  |  Training loss 1.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:28<00:00, 10.32it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:49,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:22:57.782572  |  Epoch 29  |  Training loss 1.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:41<00:00,  7.07it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:55,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:23:39.237616  |  Epoch 30  |  Training loss 1.327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:27<00:00, 10.51it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:44,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:24:07.118926  |  Epoch 31  |  Training loss 1.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.53it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:49,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:24:28.767620  |  Epoch 32  |  Training loss 1.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.25it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:42,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:24:50.874428  |  Epoch 33  |  Training loss 1.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.09it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:47,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:25:13.257683  |  Epoch 34  |  Training loss 1.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.49it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:57,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:25:36.716886  |  Epoch 35  |  Training loss 1.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.52it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:42,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:25:58.381948  |  Epoch 36  |  Training loss 1.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.92it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:38,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:26:19.435148  |  Epoch 37  |  Training loss 1.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.75it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:40,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:26:42.415888  |  Epoch 38  |  Training loss 1.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.87it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:27:05.186976  |  Epoch 39  |  Training loss 1.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.31it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:48,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:27:28.986342  |  Epoch 40  |  Training loss 1.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 12.01it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:56,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:27:53.377533  |  Epoch 41  |  Training loss 1.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.94it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:57,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:28:16.030068  |  Epoch 42  |  Training loss 1.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:24<00:00, 11.95it/s]\n",
      "Epoch progression:   0%|          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:28:40.551328  |  Epoch 43  |  Training loss 1.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.30it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:50,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:29:04.374897  |  Epoch 44  |  Training loss 1.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 13.28it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:49,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:29:26.440529  |  Epoch 45  |  Training loss 1.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:23<00:00, 12.36it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:53,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:29:50.155960  |  Epoch 46  |  Training loss 1.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:22<00:00, 12.98it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:41,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:30:12.729213  |  Epoch 47  |  Training loss 1.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.57it/s]\n",
      "Epoch progression:   0%|          | 1/293 [00:00<00:46,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:30:34.317575  |  Epoch 48  |  Training loss 1.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch progression: 100%|██████████| 293/293 [00:21<00:00, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-04 14:30:56.098043  |  Epoch 49  |  Training loss 1.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, opt, loss, 50, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Do not be afraid Gandalf had wit Sam light went their livin. His heavy deencefullow only in thir line, and called nowary felt bum he beyond-mitting to them beast, but is he need side now known you and there becaughared night some love and made no proving that he sprath,' said Pippin. `Come and master,' said Aragorn,' but the rider and becomed is. Unce you have like the mich of Bilbad Treebeard he must have you becile you on the Lord now had darce-foat companioned! You hasped, every kind graving but Boromir length in rike out. A patch of Cirith and Pernying, summoted of the road there few a news pilla.\n",
      "   `So, well, without anxifuses, from the way in Years that have been polding it as then he capt to ode then and he stood by the save of the passion!'\n",
      "   `Niding they foul there was friends of the linquentile south sair, efter of Moria curt. His thought there may was the new leave hideep rappond, howed\n",
      "      Let behave his bruilly, dim into a man part side and they healds seemed in the gung peril comps"
     ]
    }
   ],
   "source": [
    "seq_seed = \"'Do not be afra\"\n",
    "\n",
    "seq_seed_tensor = torch.zeros((1, L, len(vocab_dict)))\n",
    "for i, c in enumerate(seq_seed):\n",
    "    seq_seed_tensor[0, i] = vocab_dict[c]\n",
    "\n",
    "generate_text_with_sampling(model, seq_seed_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.61\n",
      "Accuracy val: 0.60\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.6062179166666667, 'val': 0.6008624627206535}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model, val_loader, train_loader)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}